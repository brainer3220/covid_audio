{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "from glob import glob"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.has_mps else \"cpu\")\n",
    "epochs = 32\n",
    "batch_size = 16\n",
    "\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path, is_train=True):\n",
    "        self.path = path\n",
    "        self.is_train = is_train\n",
    "        self.mel_path = path + \"mel\"\n",
    "        self.wav_path = path + \"audio\"\n",
    "        self.mel_list = glob(self.mel_path + \"/*.npy\")\n",
    "        self.wav_list = glob(self.wav_path + \"/*.npy\")\n",
    "        self.hop_length = 256\n",
    "        self.seq_len = 32\n",
    "\n",
    "        if self.is_train:\n",
    "            self.df = pd.read_csv(\"data/train_data.csv\")\n",
    "            self.y = self.df[\"covid19\"]\n",
    "        else:\n",
    "            self.df = pd.read_csv(\"data/test_data.csv\")\n",
    "\n",
    "        self.mel_files = glob(self.mel_path + \"/*.npy\")\n",
    "        self.wav_files = glob(self.wav_path + \"/*.wav\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.wav_list)\n",
    "\n",
    "    def random_select(self):\n",
    "        self.random_covid = bool(random.randint(0, 1))\n",
    "\n",
    "        if self.random_covid: self.data_list = self.df[self.df[\"covid19\"] == 1].index.tolist()\n",
    "        else: self.data_list = self.df[self.df[\"covid19\"] == 0].index.tolist()\n",
    "\n",
    "        self.index_list = self.data_list[random.randint(0, len(self.data_list)-1)]\n",
    "\n",
    "        return self.index_list\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_train: index = self.random_select()\n",
    "        else: index = idx\n",
    "\n",
    "        mel = np.load(self.mel_list[index])\n",
    "        mel = torch.from_numpy(mel).float()\n",
    "        start = random.randint(0, mel.size(1) - self.seq_len - 1)\n",
    "        wav = np.load(self.wav_list[index])\n",
    "        wav = torch.from_numpy(wav).float()\n",
    "        start *= self.hop_length\n",
    "        wav = wav[start : start + self.seq_len * self.hop_length]\n",
    "\n",
    "        if self.is_train:\n",
    "            try:\n",
    "                y = self.y[index]\n",
    "            except:\n",
    "                y = 0\n",
    "            return wav.unsqueeze(0), y\n",
    "        else:\n",
    "            return wav.unsqueeze(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def decoder_sequential(input_size, output_size, *args, **kwargs):\n",
    "    return nn.Sequential(\n",
    "        weight_norm((nn.Conv1d(input_size, output_size, *args, **kwargs))),\n",
    "        nn.LeakyReLU(0.2, inplace=True)\n",
    "    )\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.discriminator = nn.ModuleList([\n",
    "            # Feature map x 1\n",
    "            nn.Sequential(\n",
    "                nn.ReflectionPad1d(7), # 7+1+7 = 15\n",
    "                weight_norm(nn.Conv1d(1, 16, kernel_size=15)),\n",
    "                nn.LeakyReLU(0.2, inplace=True) # modify the input\n",
    "            ),\n",
    "            # Downsampling layer Feature map x 4\n",
    "            decoder_sequential(16, 64, kernel_size=41, stride=4, padding=20, groups=4),\n",
    "            decoder_sequential(64, 256, kernel_size=41, stride=4, padding=20, groups=16),\n",
    "            decoder_sequential(256, 1024, kernel_size=41, stride=4, padding=20, groups=64),\n",
    "            decoder_sequential(1024, 1024, kernel_size=41, stride=4, padding=20, groups=256),\n",
    "            # Feature map x 1\n",
    "            nn.Sequential(\n",
    "                weight_norm(nn.Conv1d(1024, 1024, kernel_size=5, padding=2)),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            ),\n",
    "            # Output x 1\n",
    "            weight_norm(nn.Conv1d(1024, 1, kernel_size=3, padding=1))\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature_map = []\n",
    "        for module in self.discriminator:\n",
    "            x = module(x)\n",
    "            feature_map.append(x)\n",
    "        return feature_map\n",
    "\n",
    "class MultiScale(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.ModuleList([\n",
    "            Discriminator() for _ in range(3)\n",
    "        ])\n",
    "\n",
    "        self.avgpool = nn.AvgPool1d(kernel_size=4, stride=2, padding=1, count_include_pad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        result = []\n",
    "        for idx, module in enumerate(self.block):\n",
    "            result.append(module(x))\n",
    "            if idx <= 1:\n",
    "                x = self.avgpool(x)\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class Disc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.out_layer = nn.Sequential(\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(8192, 4196),\n",
    "            nn.Conv1d(1, 1, kernel_size=1),\n",
    "            nn.Linear(4196, 1024),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(1, 1, kernel_size=1),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Flatten(),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # out = self.in_layer(x)\n",
    "        # print(out.shape)\n",
    "        return self.out_layer(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(path=\"./data/train/\")\n",
    "test_dataset = CustomDataset(path=\"./data/test/\", is_train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader= DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "checkpoint_path = glob(\"MelGAN-pytorch/ckpt/train/ckpt-*.pt\")[-1]\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_scale = MultiScale()\n",
    "multi_scale.load_state_dict(checkpoint[\"D\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-2.2815e-03, -1.5467e-03,  5.2056e-04,  ..., -1.5382e-04,\n          -9.4758e-05, -1.4260e-05]]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))[0].unsqueeze(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "for param in multi_scale.parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "disc = Disc().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nDisc                                     [1, 1]                    --\n├─Sequential: 1-1                        [1, 1]                    --\n│    └─LeakyReLU: 2-1                    [1, 1, 8192]              --\n│    └─Linear: 2-2                       [1, 1, 4196]              34,377,828\n│    └─Conv1d: 2-3                       [1, 1, 4196]              2\n│    └─Linear: 2-4                       [1, 1, 1024]              4,297,728\n│    └─Linear: 2-5                       [1, 1, 512]               524,800\n│    └─LeakyReLU: 2-6                    [1, 1, 512]               --\n│    └─Conv1d: 2-7                       [1, 1, 512]               2\n│    └─Linear: 2-8                       [1, 1, 64]                32,832\n│    └─Linear: 2-9                       [1, 1, 1]                 65\n│    └─Flatten: 2-10                     [1, 1]                    --\n│    └─LeakyReLU: 2-11                   [1, 1]                    --\n│    └─Sigmoid: 2-12                     [1, 1]                    --\n==========================================================================================\nTotal params: 39,233,257\nTrainable params: 39,233,257\nNon-trainable params: 0\nTotal mult-adds (M): 39.24\n==========================================================================================\nInput size (MB): 0.03\nForward/backward pass size (MB): 0.08\nParams size (MB): 156.93\nEstimated Total Size (MB): 157.05\n=========================================================================================="
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(disc, (1, 1, 8192))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "optimizer = optim.NAdam(disc.parameters(), lr=0.002)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "val = torch.FloatTensor(next(iter(train_dataset))[0].unsqueeze(0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([16, 1, 8192])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = []\n",
    "for i, (x, y) in enumerate(train_loader):\n",
    "    for j in x:\n",
    "        ls.append(j)\n",
    "    break\n",
    "\n",
    "out = torch.stack(ls).to(device)\n",
    "out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "No model found or model checkpoing load failed\n",
      "Epoch: 0, Step: 0, Loss: 0.7237203121185303\n",
      "Epoch: 0, Step: 100, Loss: 0.6931471824645996\n",
      "Epoch: 0, Step: 200, Loss: 0.6931471824645996\n",
      "Epoch: 1, Step: 0, Loss: 0.6931471824645996\n",
      "Epoch: 1, Step: 100, Loss: 0.6931471824645996\n",
      "Epoch: 1, Step: 200, Loss: 0.6931471824645996\n",
      "Epoch: 2, Step: 0, Loss: 0.6931471824645996\n",
      "Epoch: 2, Step: 100, Loss: 0.6931471824645996\n",
      "Epoch: 2, Step: 200, Loss: 0.6931471824645996\n",
      "Epoch: 3, Step: 0, Loss: 0.6931471824645996\n",
      "Epoch: 3, Step: 100, Loss: 0.6931471824645996\n",
      "Epoch: 3, Step: 200, Loss: 0.6931471824645996\n",
      "Epoch: 4, Step: 0, Loss: 0.6931471824645996\n",
      "Epoch: 4, Step: 100, Loss: 0.6931471824645996\n",
      "Epoch: 4, Step: 200, Loss: 0.6931471824645996\n",
      "Epoch: 5, Step: 0, Loss: 0.6931471824645996\n",
      "Epoch: 5, Step: 100, Loss: 0.6931471824645996\n",
      "Epoch: 5, Step: 200, Loss: 0.6931471824645996\n",
      "Epoch: 6, Step: 0, Loss: 0.6931471824645996\n",
      "Epoch: 6, Step: 100, Loss: 0.6931471824645996\n",
      "Epoch: 6, Step: 200, Loss: 0.6931471824645996\n",
      "Epoch: 7, Step: 0, Loss: 0.6931471824645996\n",
      "Epoch: 7, Step: 100, Loss: 0.6931471824645996\n",
      "Epoch: 7, Step: 200, Loss: 0.6931471824645996\n",
      "Epoch: 8, Step: 0, Loss: 0.6931471824645996\n",
      "Epoch: 8, Step: 100, Loss: 0.6931471824645996\n",
      "Epoch: 8, Step: 200, Loss: 0.6931471824645996\n",
      "Epoch: 9, Step: 0, Loss: 0.6931471824645996\n",
      "Epoch: 9, Step: 100, Loss: 0.6931471824645996\n",
      "Epoch: 9, Step: 200, Loss: 0.6931471824645996\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_37692/1805300941.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[0mmulti_scale\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meval\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m     \u001B[0mdisc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m     \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mG:\\Programdata\\envs\\covid_audio\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    528\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    529\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 530\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    531\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    532\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mG:\\Programdata\\envs\\covid_audio\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    568\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    569\u001B[0m         \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 570\u001B[1;33m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    571\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    572\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mG:\\Programdata\\envs\\covid_audio\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 49\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     50\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mG:\\Programdata\\envs\\covid_audio\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 49\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     50\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_37692/2885015408.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     38\u001B[0m         \u001B[0mmel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m         \u001B[0mstart\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mseq_len\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 40\u001B[1;33m         \u001B[0mwav\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwav_list\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     41\u001B[0m         \u001B[0mwav\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwav\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m         \u001B[0mstart\u001B[0m \u001B[1;33m*=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhop_length\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mG:\\Programdata\\envs\\covid_audio\\lib\\site-packages\\numpy\\lib\\npyio.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001B[0m\n\u001B[0;32m    428\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mformat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen_memmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmmap_mode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    429\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 430\u001B[1;33m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001B[0m\u001B[0;32m    431\u001B[0m                                          pickle_kwargs=pickle_kwargs)\n\u001B[0;32m    432\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mG:\\Programdata\\envs\\covid_audio\\lib\\site-packages\\numpy\\lib\\format.py\u001B[0m in \u001B[0;36mread_array\u001B[1;34m(fp, allow_pickle, pickle_kwargs)\u001B[0m\n\u001B[0;32m    754\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misfileobj\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    755\u001B[0m             \u001B[1;31m# We can use the fast fromfile() function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 756\u001B[1;33m             \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfromfile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcount\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcount\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    757\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    758\u001B[0m             \u001B[1;31m# This is not a real file. We have to read it the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Start training\")\n",
    "multi_scale.to(device)\n",
    "disc.to(device)\n",
    "\n",
    "try:\n",
    "    disc.load_state_dict(torch.load(glob(\"model/eval-*.pt\")[-1], map_location=device))\n",
    "    print(\"Loaded model\")\n",
    "except:\n",
    "    print(\"No model found or model checkpoing load failed\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    multi_scale.eval()\n",
    "    disc.train()\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device).unsqueeze(1).type(torch.float)\n",
    "        # print(\"x\", x.shape)\n",
    "        # print(\"y\", y.shape)\n",
    "\n",
    "        x_multiscale = [k for k in [j for j in x]]\n",
    "\n",
    "        x_multiscale = torch.stack(x_multiscale).to(device)\n",
    "        # print(\"x_multiscale\", x_multiscale.shape)\n",
    "\n",
    "        disc.zero_grad()\n",
    "        out = disc(x_multiscale).type(torch.float)\n",
    "        # print(\"disc out\", out.shape)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch: {epoch}, Step: {i}, Loss: {loss.item()}\")\n",
    "    if epoch % 1 == 0:\n",
    "        torch.save(disc.state_dict(), f\"model/eval-{epoch}.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nDisc                                     [1, 1]                    --\n├─Sequential: 1-1                        [1, 1]                    --\n│    └─LeakyReLU: 2-1                    [1, 1, 8192]              --\n│    └─Linear: 2-2                       [1, 1, 4196]              34,377,828\n│    └─Conv1d: 2-3                       [1, 1, 4196]              2\n│    └─Linear: 2-4                       [1, 1, 1024]              4,297,728\n│    └─Linear: 2-5                       [1, 1, 512]               524,800\n│    └─LeakyReLU: 2-6                    [1, 1, 512]               --\n│    └─Conv1d: 2-7                       [1, 1, 512]               2\n│    └─Linear: 2-8                       [1, 1, 64]                32,832\n│    └─Linear: 2-9                       [1, 1, 1]                 65\n│    └─Flatten: 2-10                     [1, 1]                    --\n│    └─LeakyReLU: 2-11                   [1, 1]                    --\n│    └─Sigmoid: 2-12                     [1, 1]                    --\n==========================================================================================\nTotal params: 39,233,257\nTrainable params: 39,233,257\nNon-trainable params: 0\nTotal mult-adds (M): 39.24\n==========================================================================================\nInput size (MB): 0.03\nForward/backward pass size (MB): 0.08\nParams size (MB): 156.93\nEstimated Total Size (MB): 157.05\n=========================================================================================="
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(disc, (1, 1, 8192))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Export model to ONNX format"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# torch.onnx.export(multi_scale.to('cpu'), torch.randn(1, 1, 108486), \"MelGAN MultiScale.onnx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "torch.onnx.export(disc.to(\"cpu\"), torch.randn(1, 1, 8192), \"Discriminator.onnx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = glob(\"model/eval-*.pt\")[-1]\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "disc.load_state_dict(checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 359/359 [02:22<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "disc.eval()\n",
    "disc.to(device)\n",
    "\n",
    "predict_list = np.empty(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x in tqdm(test_loader):\n",
    "        x = x.to(device)\n",
    "        x_multiscale = [k for k in [j for j in x]]\n",
    "        x_multiscale = torch.stack(x_multiscale).to(device)\n",
    "        out = disc(x_multiscale).type(torch.float)\n",
    "        predict_list = np.concatenate((predict_list, out.cpu().numpy().reshape(-1)), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_list = predict_list.astype(int)\n",
    "predict_list[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "array([], dtype=int32)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_list[predict_list == 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}